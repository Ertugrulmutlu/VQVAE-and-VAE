import os
import torch
from PIL import Image
from torchvision import transforms
import numpy as np
import matplotlib.pyplot as plt

# --- Ayarlar ---
image_path = r".\\Datas\\test\\test1.png"
reconstructed_path = r".\\Datas\\test\\reconstructed_vqvae.jpg"
model_path = "vqvae_model.pt"

# --- Orijinal boyutu Ã¶lÃ§ ---
original_size = os.path.getsize(image_path)

# --- GÃ¶rseli yÃ¼kle ve dÃ¶nÃ¼ÅŸtÃ¼r ---
img = Image.open(image_path).convert("RGB")
transform = transforms.Compose([
    transforms.Resize((128, 128)),  # EÄŸitimde kullandÄ±ÄŸÄ±n boyut neyse onunla aynÄ± olmalÄ±
    transforms.ToTensor()
])
input_tensor = transform(img).unsqueeze(0)  # [1, 3, 64, 64]

# --- Modeli yÃ¼kle ---
from Utils.model import VQVAE  # Modelinin dosya adÄ± buysa
model = VQVAE()
model.load_state_dict(torch.load(model_path, map_location="cpu"))
model.eval()

# --- Encodeâ€“Decode ---
with torch.no_grad():
    recon, _ = model(input_tensor)

# --- Yeniden gÃ¶rsele Ã§evir ---
recon_img = recon.squeeze().permute(1, 2, 0).numpy()
recon_img = (recon_img * 255).astype(np.uint8)
recon_pil = Image.fromarray(recon_img)
recon_pil.save(reconstructed_path, quality=85)  # JPEG formatta kaydet

# --- Yeniden Ã¼retilmiÅŸ gÃ¶rselin boyutu ---
reconstructed_size = os.path.getsize(reconstructed_path)

# --- SonuÃ§larÄ± yazdÄ±r ---
compression_rate = original_size / reconstructed_size
print(f"ğŸ–¼ï¸ Original:      {original_size / 1024:.2f} KB")
print(f"ğŸ” Reconstructed: {reconstructed_size / 1024:.2f} KB")
print(f"ğŸ“‰ Compression Rate: {compression_rate:.2f}x")

# --- GÃ¶rselleri gÃ¶ster ---
fig, axs = plt.subplots(1, 2, figsize=(8, 4))
axs[0].imshow(img)
axs[0].set_title("Original")
axs[0].axis("off")
axs[1].imshow(recon_pil)
axs[1].set_title("Reconstructed (VQ-VAE)")
axs[1].axis("off")
plt.tight_layout()
plt.show()

